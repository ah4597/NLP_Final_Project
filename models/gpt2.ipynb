{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kr2Z8ODIkBIH"
      },
      "outputs": [],
      "source": [
        "import gpt_2_simple as gpt2\n",
        "\n",
        "model_name = \"117M\" # \"355M\" for larger model (it's 1.4 GB)\n",
        "gpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/117M/\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.finetune(sess,\n",
        "              '../corpus_data/test_titles.txt',\n",
        "              model_name=model_name,\n",
        "              steps=250,\n",
        "              save_every=50,\n",
        "              sample_every=25)   # steps is max number of training steps\n",
        "\n",
        "gpt2.generate(sess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "SLWNSprkmFRI",
        "outputId": "cce2e90e-d882-4491-9930-d7f1260dd0a7"
      },
      "outputs": [],
      "source": [
        "import gpt_2_simple as gpt2\n",
        "import tensorflow as tf\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "-AqWOMuamMNu",
        "outputId": "b6e9ce15-c8af-4fb6-84d7-a814590acc14"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "datafiles = ['yake1', 'yake3', 'yake5']\n",
        "\n",
        "for datafile in datafiles:\n",
        "    output = open(f'../outputs/gpt2/{datafile}_output.csv', 'w', encoding='utf-8')\n",
        "    with open(f'../data/{datafile}.json') as json_file:\n",
        "        data = json.load(json_file)\n",
        "        d = dict(list(data.items())[:20])\n",
        "        for index in tqdm(d):\n",
        "          output.write(index + ',')\n",
        "          for i in range(3):\n",
        "            text = gpt2.generate(sess,\n",
        "                                  length=10,\n",
        "                                  temperature=0.7,\n",
        "                                  prefix=d[index][i],\n",
        "                                  nsamples=1,\n",
        "                                  batch_size=1,\n",
        "                                  return_as_list=True)\n",
        "            t = text[0].title()\n",
        "            t = t.replace('<|Startoftext|>', '').replace('\\n', '') # remove extraneous stuff\n",
        "            #t = t[:t.index('<|Endoftext|>')] # only get one title\n",
        "            output.write(t+',')\n",
        "\n",
        "          output.write('\\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gpt2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
